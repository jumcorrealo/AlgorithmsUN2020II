{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NumPy\n",
    "by Maxwell Margenot\n",
    "\n",
    "Part of the Quantopian Lecture Series:\n",
    "\n",
    "* [www.quantopian.com/lectures](https://www.quantopian.com/lectures)\n",
    "* [github.com/quantopian/research_public](https://github.com/quantopian/research_public)\n",
    "\n",
    "Notebook released under the Creative Commons Attribution 4.0 License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy is an incredibly powerful package in Python that is ubiquitous throughout the Quantopian platform. It has strong integration with Pandas, another tool we will be covering in the lecture series. NumPy adds support for multi-dimensional arrays and mathematical functions that allow you to easily perform linear algebra calculations. This lecture will be a collection of linear algebra examples computed using NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic NumPy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic way that we could make use of NumPy in finance is calculating the mean return of a portfolio. Say that we have a list containing the historical return of several stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.5, 5, 2, 8, 4.2]\n",
      "{0, 2, 3}\n",
      "(0, 0, 4, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "stock_list = [3.5, 5, 2, 8, 4.2]\n",
    "stock_set = {3,2,3,2,0}\n",
    "stock_tuple = (0,0,4,2,1)\n",
    "print stock_list\n",
    "print stock_set\n",
    "print stock_tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make an array by calling a function on the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.5  5.   2.   8.   4.2] <class 'numpy.ndarray'>\n",
      "{0, 2, 3} <class 'numpy.ndarray'>\n",
      "[0 0 4 2 1] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "returns = np.array(stock_list)\n",
    "returns2 = np.array(stock_set)\n",
    "returns3 = np.array(stock_tuple)\n",
    "print returns, type(returns)\n",
    "print returns2, type(returns2)\n",
    "print returns3, type(returns3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the type of our array is 'ndarray', not just 'array'. This is because NumPy arrays can be created with multiple dimensions. If we pass np.array() a list of lists, it will create a 2-dimensional array. If we pass a list of lists of lists, it will create a 3-dimensional array, and so on and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]] <class 'numpy.ndarray'>\n",
      "[{1, 2} {3, 4}] <class 'numpy.ndarray'>\n",
      "[[5 6]\n",
      " [7 8]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([{1,2}, {3,4}])\n",
    "C = np.array([(5,6), (7,8)])\n",
    "print A, type(A)\n",
    "print B, type(B)\n",
    "print C, type(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the dimensions of an array by looking at its `shape` member variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(2,)\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "print A.shape\n",
    "print B.shape\n",
    "print C.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays are indexed in much the same way as lists in Python. Elements of a list begin indexing from $0$ and end at $n - 1$, where $n$ is the length of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5 4.2\n",
      "0 4.2\n"
     ]
    }
   ],
   "source": [
    "print returns[0], returns[len(returns) - 1]\n",
    "#print returns2[0], returns[len(returns2) - 1]\n",
    "print returns3[0], returns[len(returns3) -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a slice of an array using a colon, just like in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.  2.]\n",
      "[0 4]\n"
     ]
    }
   ],
   "source": [
    "print returns[1:3]\n",
    "print returns3[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slice of an array, like in a list, will select a group of elements in the array starting from the first element indicated and going up to (but not including) the last element indicated.\n",
    "\n",
    "In the case of multidimensional arrays, many of the same conventions with slicing and indexing hold. We can access the first column of a 2-dimensional array like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3]\n",
      "[5 7]\n"
     ]
    }
   ],
   "source": [
    "print A[:, 0]\n",
    "#print B[:, 0]\n",
    "print C[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the first row of a 2-dimensional array like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[5 6]\n"
     ]
    }
   ],
   "source": [
    "print A[0, :]\n",
    "print C[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that each slice of the array returns yet another array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print type(A[0,:])\n",
    "print type(C[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing only one index to a 2-dimensional array will result in returning the row with the given index as well, providing us with another way to access individual rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "{1, 2}\n",
      "[5 6]\n"
     ]
    }
   ],
   "source": [
    "print A[0]\n",
    "print B[0]\n",
    "print C[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the index of an individual element will return only the element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print A[1, 1]\n",
    "print C[1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Array functions\n",
    "\n",
    "Functions built into NumPy can be easily called on arrays. Most functions are applied to an array element-wise (as scalar multiplication is). For example, if we call `log()` on an array, the logarithm will be taken of each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.25276297  1.60943791  0.69314718  2.07944154  1.43508453]\n",
      "[       -inf        -inf  1.38629436  0.69314718  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print np.log(returns)\n",
    "print np.log(returns3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions return a single value. This is because they treat the array as a collection (similar to a list), performing the designated function. For example, the `mean()` function will do exactly what you expect, calculating the mean of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.54\n",
      "1.4\n"
     ]
    }
   ],
   "source": [
    "print np.mean(returns)\n",
    "print np.mean(returns3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the `max()` function will return the maximum element of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "{0, 2, 3}\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print np.max(returns)\n",
    "print np.max(returns2)\n",
    "print np.max(returns3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further reading on the universal functions in NumPy, check out the [documentation](https://docs.scipy.org/doc/numpy/user/quickstart.html#universal-functions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return to the returns\n",
    "\n",
    "Now let's modify our returns array with scalar values. If we add a scalar value to an array it will be added to every element of the array. If we multiply an array by a scalar value it will be multiplied against every element of the array. If we do both, both will happen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.5  5.   2.   8.   4.2]\n",
      "[ 12.   15.    9.   21.   13.4]\n",
      "[0 0 4 2 1]\n",
      "[ 2  2 14  8  5]\n"
     ]
    }
   ],
   "source": [
    "print returns\n",
    "print returns*2 + 5\n",
    "print returns3\n",
    "print returns3 *3 +2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy also has functions specifically built to operate on arrays. Let's take the mean and standard deviation of this group of returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  4.54 Std Dev:  1.99158228552\n",
      "Mean:  1.4 Std Dev:  1.49666295471\n"
     ]
    }
   ],
   "source": [
    "print \"Mean: \", np.mean(returns), \"Std Dev: \", np.std(returns)\n",
    "print \"Mean: \", np.mean(returns3), \"Std Dev: \", np.std(returns3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simulate a universe of stocks using NumPy's functions. First we need to create the arrays to hold the assets and returns that we will use to build a portfolio. This is because arrays are created with a fixed size. Their dimensions can't be changed without creating a new array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "assets = np.zeros((N, 100))\n",
    "returns = np.zeros((N, 100))\n",
    "print assets\n",
    "print returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, `zeroes()`, creates a NumPy array with the given dimensions that is entirely filled in with $0$. We can pass a single value or a tuple of as many dimensions as we like. Passing in the tuple `(N, 100)`, will return a two-dimensional array with $N$ rows and $100$ columns. Our result is a $N \\times 100$ array.\n",
    "\n",
    "Now we will simulate a base asset. We want the universe of stocks to be correlated with each other so we will use this initial value to generate the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.04057004  0.99079741  0.96347394  1.01137596  0.99617872  0.98896927\n",
      "   1.01982629  0.98081701  1.01888362  0.96870244  1.01268562  1.01128325\n",
      "   0.98978062  1.05981483  1.02912992  1.00249722  1.02674654  1.062045\n",
      "   1.02694915  1.01493026  0.99524858  0.9847015   1.03538536  1.02133252\n",
      "   1.00425063  1.04252847  1.01464401  1.00277773  1.01131729  0.98420459\n",
      "   1.00628192  1.0007497   1.00900688  1.02581819  1.018102    0.98442482\n",
      "   1.03613208  1.02822971  1.00894951  1.04362615  1.07721633  0.98320653\n",
      "   1.0100155   0.99274538  1.01323585  0.99402579  1.00075163  1.00545389\n",
      "   1.0028805   1.01157218  1.03963417  1.041655    1.00821478  1.04669362\n",
      "   1.00521402  1.04984326  1.01268295  0.99640184  0.99771279  0.96301078\n",
      "   0.96295562  0.98623728  1.03280631  1.05493372  1.03634318  1.0336032\n",
      "   0.99556382  1.00709119  1.00239324  0.99345974  1.01125187  0.99027072\n",
      "   1.04149898  1.02406908  1.00123094  1.01402969  0.99134363  1.04904629\n",
      "   0.98220788  1.00476188  1.00938391  0.97209595  1.00096789  1.05018647\n",
      "   0.97507788  1.00066817  1.00436045  1.02905463  1.02556182  0.99089559\n",
      "   1.03401204  0.98134469  1.03425464  1.00082399  0.95250949  1.00837737\n",
      "   1.00798874  0.94451549  0.99140058  0.97057601]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]]\n",
      "[[ 1.04057004  1.0309941   0.99333595  1.00463609  1.0007971   0.98975758\n",
      "   1.0093808   0.99001785  1.00871297  0.97714271  0.98953838  1.00070359\n",
      "   0.99047702  1.04972223  1.08030055  1.08299829  1.11196475  1.18095661\n",
      "   1.21278238  1.23088954  1.22504107  1.20629978  1.24898514  1.27562913\n",
      "   1.28105136  1.33553252  1.35509007  1.35885414  1.37423268  1.35252611\n",
      "   1.36102257  1.36204293  1.37431069  1.4097929   1.43531297  1.41295772\n",
      "   1.46401082  1.50533942  1.51881148  1.58507137  1.70746477  1.6787905\n",
      "   1.69560442  1.68330346  1.70558341  1.6953939   1.6966682   1.70592165\n",
      "   1.71083556  1.73063365  1.79922588  1.87417263  1.88956854  1.97779933\n",
      "   1.98811162  2.08720559  2.11367751  2.10607215  2.10125512  2.02353133\n",
      "   1.94857088  1.92175325  1.98479888  2.09383126  2.16992774  2.24284426\n",
      "   2.23289459  2.24872846  2.25411021  2.23936775  2.26456483  2.24253225\n",
      "   2.33559506  2.39181068  2.39475485  2.42835251  2.40733179  2.52540248\n",
      "   2.4804702   2.49228191  2.51566927  2.4454719   2.44783886  2.57068725\n",
      "   2.50662028  2.50829513  2.51923242  2.5924278   2.65869498  2.63448913\n",
      "   2.72409348  2.67327467  2.76484675  2.76712495  2.63571278  2.65779311\n",
      "   2.67902552  2.53038111  2.5086213   2.43480765]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "R_1 = np.random.normal(1.01, 0.03, 100)\n",
    "returns[0] = R_1\n",
    "assets[0] = np.cumprod(R_1)\n",
    "print returns\n",
    "print assets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `random` module in NumPy is exceedingly useful. It contains methods for sampling from many different probability distributions, some of which are covered in the [random variables lecture](https://www.quantopian.com/lectures/random-variables) in the Quantopian lecture series. In this case we draw $N = 100$ random samples from a normal distribution with mean $1.01$ and standard deviation $0.03$. We treat these as the daily percentage returns of our asset and take the cumulative product of these samples to get the current price.\n",
    "\n",
    "The way we have generated our universe, the the individual $R_i$ vectors are each 1-dimensional arrays and the `returns` and `assets` variables contain 2-dimensional arrays. Above, we set the initial row of both `returns` and `assets` to be the first $R_i$ vector and the cumulative asset price based on those returns, respectively.\n",
    "\n",
    "We will now use this base asset to create a few other random assets that are correlated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92448958305959561, 0.89415429307579952, 1.6184848116814532, 1.0854659362026453, 1.1123790703315484, 1.0191939276416484, 1.0966365273611389, 1.2977155065377888, 1.3029463354748305, 0.86233580078900474]\n",
      "[0.024880995576304563, 0.03071297062779297, 0.032494912915281941, 0.031940665051683886, 0.030510291892146751, 0.031670831560967477, 0.027044269378347342, 0.032225957283343473, 0.031256878621791058, 0.028455818786596376]\n"
     ]
    }
   ],
   "source": [
    "# Generate assets that are correlated with R_1\n",
    "for i in range(1, N):\n",
    "    R_i = R_1 + np.random.normal(0.001, 0.02, 100)\n",
    "    returns[i] = R_i # Set each row of returns equal to the new R_i array\n",
    "    assets[i] = np.cumprod(R_i)\n",
    "    \n",
    "mean_returns = [(np.mean(R) - 1)*100 for R in returns]\n",
    "return_volatilities = [np.std(R) for R in returns]\n",
    "print mean_returns\n",
    "print return_volatilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate the remaining $N - 1$ securities that we want in our universe by adding random noise to $R_1$. This ensures that our $N - 1$ other assets will be correlated with the base asset because they have some underlying information that is shared.\n",
    "\n",
    "Let's plot what the mean return of each asset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0UAAAH6CAYAAADIhOc8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTDDZS9+vox8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fca2cf01438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.arange(len(mean_returns)), mean_returns)\n",
    "#plt.bar(np.arange(len(return_volatilities)), return_volatilities)\n",
    "plt.xlabel('Stock')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('Returns for {0} Random Assets'.format(N));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Expected Return\n",
    "\n",
    "So we have a universe of stocks. Great! Now let's put them together in a portfolio and calculate its expected return and risk.\n",
    "\n",
    "We will start off by generating $N$ random weights for each asset in our portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10207767  0.12505063  0.11709909  0.08943459  0.100711    0.04121931\n",
      "  0.04512445  0.14617887  0.12856417  0.1045402 ]\n"
     ]
    }
   ],
   "source": [
    "weights = np.random.uniform(0, 1, N)\n",
    "weights = weights/np.sum(weights)\n",
    "print weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to rescale the weights so that they all add up to $1$. We do this by scaling the weights vector by the sum total of all the weights. This step ensures that we will be using $100\\%$ of the portfolio's cash.\n",
    "\n",
    "To calculate the mean return of the portfolio, we have to scale each asset's return by its designated weight. We can pull each element of each array and multiply them individually, but it's quicker to use NumPy's linear algebra methods. The function that we want is `dot()`. This will calculate the dot product between two arrays for us. So if $v = \\left[ 1, 2, 3 \\right]$ and $w = \\left[4, 5, 6 \\right]$, then:\n",
    "\n",
    "$$ v \\cdot w = 1 \\times 4 + 2 \\times 5 + 3 \\times 6 $$\n",
    "\n",
    "For a one-dimensional vector, the dot product will multiply each element pointwise and add all the products together! In our case, we have a vector of weights, $\\omega = \\left[ \\omega_1, \\omega_2, \\dots \\omega_N\\right]$ and a vector of returns, $\\mu = \\left[ \\mu_1, \\mu_2, \\dots, \\mu_N\\right]$. If we take the dot product of these two we will get:\n",
    "\n",
    "$$ \\omega \\cdot \\mu = \\omega_1\\mu_1 + \\omega_2\\mu_2 + \\dots + \\omega_N\\mu_N = \\mu_P $$\n",
    "\n",
    "This yields the sum of all the asset returns scaled by their respective weights. This the the portfolio's overall expected return!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected return of the portfolio:  1.14366958112\n"
     ]
    }
   ],
   "source": [
    "p_returns = np.dot(weights, mean_returns)\n",
    "print \"Expected return of the portfolio: \", p_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the mean return is fairly intuitive and does not require too much explanation of linear algebra. However, calculating the variance of our portfolio requires a bit more background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beware of NaN values\n",
    "\n",
    "Most of the time, all of these calculations will work without an issue. However, when working with real data we run the risk of having `nan` values in our arrays. This is NumPy's way of saying that the data there is missing or doesn't exist. These `nan` values can lead to errors in mathematical calculations so it is important to be aware of whether your array contains `nan` values and to know how to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.   1.   5.   2.  nan   4.   5.]\n"
     ]
    }
   ],
   "source": [
    "v = np.array([3, 1, 5, 2, np.nan, 4, 5])\n",
    "print v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we try to take the mean of this array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print np.mean(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, `nan` values can have a large impact on our calculations. Fortunately, we can check for `nan` values with the `isnan()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False,  True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `isnan()` on an array will call the function on each value of the array, returning a value of `True` if the element is `nan` and `False` if the element is valid. Now, knowing whether your array contains `nan` values is all well and good, but how do we remove `nan`s? Handily enough, NumPy arrays can be indexed by boolean values (`True` or `False`). If we use a boolean array to index an array, we will remove all values of the array that register as `False` under the condition. We use the `isnan()` function in create a boolean array, assigning a `True` value to everything that is *not* `nan` and a `False` to the `nan`s and we use that to index the same array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  1.  5.  2.  4.  5.]\n"
     ]
    }
   ],
   "source": [
    "ix = ~np.isnan(v) # the ~ indicates a logical not, inverting the bools\n",
    "print v[ix] # We can also just write v = v[~np.isnan(v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.33333333333\n"
     ]
    }
   ],
   "source": [
    "print np.mean(v[ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few shortcuts to this process in the form of NumPy functions specifically built to handle them, such as `nanmean()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.33333333333\n"
     ]
    }
   ],
   "source": [
    "print np.nanmean(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nanmean()` function simply calculates the mean of the array as if there were no `nan` values at all! There are a few more of these functions, so feel free to read more about them in the [documentation](https://docs.scipy.org/doc/numpy/user/index.html). These indeterminate values are more an issue with data than linear algebra itself so it is helpful that there are ways to handle them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Linear algebra is pervasive in finance and in general. For example, the calculation of *optimal* weights according to modern portfolio theory is done using linear algebra techniques. The arrays and functions in NumPy allow us to handle these calculations in an intuitive way. For a quick intro to linear algebra and how to use NumPy to do more significant matrix calculations, proceed to the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief foray into linear algebra\n",
    "\n",
    "Let's start with a basic overview of some linear algebra. Linear algebra comes down to the multiplication and composition of scalar and matrix values. A scalar value is just a real number that we multiply against an array. When we scale a matrix or array using a scalar, we multiply each individual element of that matrix or array by the scalar.\n",
    "\n",
    "A matrix is a collection of values, typically represented by an $m \\times n$ grid, where $m$ is the number of rows and $n$ is the number of columns. The edge lengths $m$ and $n$ do not necessarily have to be different. If we have $m = n$, we call this a square matrix. A particularly interesting case of a matrix is when $m = 1$ or $n = 1$. In this case we have a special case of a matrix that we call a vector. While there is a matrix object in NumPy we will be doing everything using NumPy arrays because they can have dimensions greater than $2$. For the purpose of this section, we will be using matrix and array interchangeably.\n",
    "\n",
    "We can express the matrix equation as:\n",
    "\n",
    "$$ y = A\\cdot x $$\n",
    "\n",
    "Where $A$ is an $m \\times n$ matrix, $y$ is a $m \\times 1$ vector, and $x$ is a $n \\times 1$ vector. On the right-hand side of the equation we are multiplying a matrix by a vector. This requires a little bit more clarification, lest we think that we can go about multiplying any matrices by any other matrices.\n",
    "\n",
    "#### Matrix multiplication\n",
    "\n",
    "With matrix multiplication, the order in which the matrices are multiplied matters. Multiplying a matrix on the left side by another matrix may be just fine, but multiplying on the right may be undefined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "        [1, 2, 3, 12, 6],\n",
    "        [4, 5, 6, 15, 20],\n",
    "        [7, 8, 9, 10, 10]        \n",
    "    ])\n",
    "B = np.array([\n",
    "        [4, 4, 2],\n",
    "        [2, 3, 1],\n",
    "        [6, 5, 8],\n",
    "        [9, 9, 9]\n",
    "    ])\n",
    "\n",
    "C = np.array([(1,1,2,3,1), (1,3,1,4,5), (3,6,5,4,3), (67,4,3,2,1), (2,3,1,4,5) ])\n",
    "\n",
    "D = np.array([(6,4,2,5,1), (2,1,3,4,5), (5,1,3,4,3), (6,4,3,22,14), (3,4,5,3,1) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the above-defined matrices, $A$ and $B$, have different dimensions. $A$ is $3 \\times 5$ and $B$ is $4 \\times 3$. The general rule of what can and cannot be multiplied in which order is based on the dimensions of the matrices. Specifically, the number of columns in the matrix on the left must be equal to the number of rows in the matrix on the right. In super informal terms, let's say that we have an $m \\times n$ matrix and a $p \\times q$ matrix. If we multiply the first by the second on the right, we get the following:\n",
    "\n",
    "$$ (m \\times n) \\cdot (p \\times q) = (m \\times q) $$\n",
    "\n",
    "So the resultant product has the same number of rows as the left matrix and the same number of columns as the right matrix. This limitation of matrix multiplication with regards to dimensions is important to keep track of when writing code. To demonstrate this, we use the `dot()` function to multiply our matrices below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 34  44  54 128 124]\n",
      " [ 21  27  33  79  82]\n",
      " [ 82 101 120 227 216]\n",
      " [108 135 162 333 324]]\n",
      "[[ 39  23  25  86  55]\n",
      " [ 56  44  51 124  80]\n",
      " [ 88  51  66 156 107]\n",
      " [440 287 166 410 125]\n",
      " [ 62  48  53 129  81]]\n",
      "[[ 353   53   42   56   42]\n",
      " [ 290   54   37   50   45]\n",
      " [ 289   51   41   51   38]\n",
      " [1521  166  111  146  127]\n",
      " [ 225   60   45   55   46]]\n"
     ]
    }
   ],
   "source": [
    "print np.dot(B, A)\n",
    "print np.dot(C, D)\n",
    "print np.dot(D, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results make sense in accordance with our rule. Multiplying a $3 \\times 5$ matrix on the right by a $4 \\times 3$ matrix results in an error while multiplying a $4 \\times 3$ matrix on the right by a $3 \\times 5$ matrix results in a $4 \\times 5$ matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 34  44  54 128 124]\n",
      " [ 21  27  33  79  82]\n",
      " [ 82 101 120 227 216]\n",
      " [108 135 162 333 324]]\n"
     ]
    }
   ],
   "source": [
    "print np.dot(B, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio Variance\n",
    "\n",
    "Let's return to our portfolio example from before. We calculated the expected return of the portfolio, but how do we calculate the variance? We start by trying to evaluate the portfolio as a sum of each individual asset, scaled by it's weight.\n",
    "\n",
    "$$ VAR[P] = VAR[\\omega_1 S_1 + \\omega_2 S_2 + \\cdots + \\omega_N S_N] $$\n",
    "\n",
    "Where $S_0, \\cdots, S_N$ are the assets contained within our universe. If all of our assets were independent of each other, we could simply evaluate this as\n",
    "\n",
    "$$ VAR[P] = VAR[\\omega_1 S_1] + VAR[\\omega_2 S_2] + \\cdots + VAR[\\omega_N S_N] = \\omega_1^2\\sigma_1^2 + \\omega_2^2\\sigma_2^2 + \\cdots + \\omega_N^2\\sigma_N^2 $$\n",
    "\n",
    "However, all of our assets depend on each other by their construction. They are all in some way related to our base asset and therefore each other. We thus have to calculate the variance of the portfolio by including the individual pairwise covariances of each asset. Our formula for the variance of the portfolio:\n",
    "\n",
    "$$ VAR[P] = \\sigma_P^2 = \\sum_i \\omega_i^2\\sigma_i^2 + \\sum_i\\sum_{i\\neq j} \\omega_i\\omega_j\\sigma_i\\sigma_j\\rho_{i, j}, \\ i, j \\in \\lbrace 1, 2, \\cdots, N \\rbrace $$\n",
    "\n",
    "Where $\\rho_{i,j}$ is the correlation between $S_i$ and $S_j$, $\\rho_{i, j} = \\frac{COV[S_i, S_j]}{\\sigma_i\\sigma_j}$. This seems exceedingly complicated, but we can easily handle all of this using NumPy arrays. First, we calculate the covariance matrix that relates all the individual stocks in our universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00062532  0.00059944  0.00062662  0.00060493  0.00062198  0.00060598\n",
      "   0.00052221  0.00060978  0.00066435  0.00054258]\n",
      " [ 0.00059944  0.00095281  0.00055448  0.00052531  0.00051755  0.00061166\n",
      "   0.00057977  0.00060135  0.00062581  0.00049561]\n",
      " [ 0.00062662  0.00055448  0.00106659  0.00067128  0.00055594  0.00057046\n",
      "   0.00052294  0.00059704  0.00066412  0.00061264]\n",
      " [ 0.00060493  0.00052531  0.00067128  0.00103051  0.00058842  0.00063782\n",
      "   0.00051274  0.00056838  0.00067243  0.00052855]\n",
      " [ 0.00062198  0.00051755  0.00055594  0.00058842  0.00094028  0.00064116\n",
      "   0.0004857   0.00066136  0.00066921  0.00053209]\n",
      " [ 0.00060598  0.00061166  0.00057046  0.00063782  0.00064116  0.00101317\n",
      "   0.00049685  0.00058854  0.00066848  0.00047469]\n",
      " [ 0.00052221  0.00057977  0.00052294  0.00051274  0.0004857   0.00049685\n",
      "   0.00073878  0.00053305  0.00052255  0.00042859]\n",
      " [ 0.00060978  0.00060135  0.00059704  0.00056838  0.00066136  0.00058854\n",
      "   0.00053305  0.001049    0.00061451  0.00055436]\n",
      " [ 0.00066435  0.00062581  0.00066412  0.00067243  0.00066921  0.00066848\n",
      "   0.00052255  0.00061451  0.00098686  0.00053516]\n",
      " [ 0.00054258  0.00049561  0.00061264  0.00052855  0.00053209  0.00047469\n",
      "   0.00042859  0.00055436  0.00053516  0.00081791]]\n"
     ]
    }
   ],
   "source": [
    "cov_mat = np.cov(returns)\n",
    "print cov_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This array is not formatted particularly nicely, but a covariance matrix is a very important concept. The covariance matrix is of the form:\n",
    "\n",
    "$$ \\left[\\begin{matrix}\n",
    "VAR[S_1] & COV[S_1, S_2] & \\cdots & COV[S_1, S_N] \\\\\n",
    "COV[S_2, S_1] & VAR[S_2] & \\cdots & COV[S_2, S_N] \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "COV[S_N, S_1] & COV[S_N, S_2] & \\cdots & VAR[S_N]\n",
    "\\end{matrix}\\right] $$\n",
    "\n",
    "So each diagonal entry is the variance of that asset at that index and each off-diagonal holds the covariance of two assets indexed by the column and row number. What is important is that once we have the covariance matrix we are able to do some very quick linear algebra to calculate the variance of the overall portfolio. We can represent the variance of the portfolio in array form as:\n",
    "\n",
    "$$ \\sigma_p^2 = \\omega \\ C \\ \\omega^\\intercal$$\n",
    "\n",
    "Where $C$ is the covariance matrix of all the assets and $\\omega$ is the array containing the weights of each individual asset. The superscript $\\intercal$ on the second $\\omega$ listed above denotes the **transpose** of $\\omega$. For a reference on the evaluation of the variance of a portfolio as a matrix equation, please see the Wikipedia article on [modern portfolio theory](https://en.wikipedia.org/wiki/Modern_portfolio_theory).\n",
    "\n",
    "The transpose of an array is what you get when you switch the rows and columns of an array. This has the effect of reflecting an array across what you might imagine as a diagonal. For example, take our array $A$ from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3 12  6]\n",
      " [ 4  5  6 15 20]\n",
      " [ 7  8  9 10 10]]\n",
      "[[4 4 2]\n",
      " [2 3 1]\n",
      " [6 5 8]\n",
      " [9 9 9]]\n",
      "[[ 1  1  2  3  1]\n",
      " [ 1  3  1  4  5]\n",
      " [ 3  6  5  4  3]\n",
      " [67  4  3  2  1]\n",
      " [ 2  3  1  4  5]]\n",
      "[[ 6  4  2  5  1]\n",
      " [ 2  1  3  4  5]\n",
      " [ 5  1  3  4  3]\n",
      " [ 6  4  3 22 14]\n",
      " [ 3  4  5  3  1]]\n"
     ]
    }
   ],
   "source": [
    "print A\n",
    "print B\n",
    "print C\n",
    "print D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transpose looks like a mirror image of the same array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  4  7]\n",
      " [ 2  5  8]\n",
      " [ 3  6  9]\n",
      " [12 15 10]\n",
      " [ 6 20 10]]\n",
      "[[4 2 6 9]\n",
      " [4 3 5 9]\n",
      " [2 1 8 9]]\n",
      "[[ 1  1  3 67  2]\n",
      " [ 1  3  6  4  3]\n",
      " [ 2  1  5  3  1]\n",
      " [ 3  4  4  2  4]\n",
      " [ 1  5  3  1  5]]\n",
      "[[ 6  2  5  6  3]\n",
      " [ 4  1  1  4  4]\n",
      " [ 2  3  3  3  5]\n",
      " [ 5  4  4 22  3]\n",
      " [ 1  5  3 14  1]]\n"
     ]
    }
   ],
   "source": [
    "print np.transpose(A)\n",
    "print np.transpose(B)\n",
    "print np.transpose(C)\n",
    "print np.transpose(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But $\\omega$ here is a 1-dimensional array, a vector! It makes perfect to take the transpose of $A$, a $3 \\times 5$ array, as the output will be a $5 \\times 3$ array, but a 1-dimensional array is not quite as intuitive. A typical 1-dimensional array can be thought of as a $1 \\times n$ horizontal vector. Thus, taking the tranpose of this array essentially means changing it into a $n \\times 1$ vertical vector. This makes sense because 1-dimensional arrays are still arrays and any multiplication done between 1-dimensional and higher dimensional arrays must keep in line with our dimensionality issue of matrix multiplication.\n",
    "\n",
    "To make a long story short, we think of $\\omega$ as $1 \\times N$ since we have $N$ securities. This makes it so that $\\omega^\\intercal$ is $N \\times 1$. Again, our covariance matrix is $N \\times N$. So the overall multiplication works out like so, in informal terms:\n",
    "\n",
    "$$ \\text{Dimensions}(\\sigma_p^2) = \\text{Dimensions}(\\omega C \\omega^\\intercal) = (1 \\times N)\\cdot (N \\times N)\\cdot (N \\times 1) = (1 \\times 1)$$\n",
    "\n",
    "Multiplying the covariance matrix on the left by the plain horizontal vector and on the right by that vector's transpose results in the calculation of a single scalar ($1 \\times 1$) value, our portfolio's variance.\n",
    "\n",
    "So knowing this, let's proceed and calculate the portfolio variance! We can easily calculate the product of these arrays by using `dot()` for matrix multiplication, though this time we have to do it twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio volatility:  0.0250521109862\n"
     ]
    }
   ],
   "source": [
    "# Calculating the portfolio volatility\n",
    "var_p = np.dot(np.dot(weights, cov_mat), weights.T)\n",
    "vol_p = np.sqrt(var_p)\n",
    "print \"Portfolio volatility: \", vol_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm this calculation, let's simply evaluate the volatility of the portfolio using only NumPy functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio volatility:  0.0250521109862\n"
     ]
    }
   ],
   "source": [
    "# Confirming calculation\n",
    "vol_p_alt = np.sqrt(np.var(np.dot(weights, returns), ddof=1))\n",
    "print \"Portfolio volatility: \", vol_p_alt\n",
    "\n",
    "#vol_p_alt2 = np.sqrt(np.var(np.dot(weights, returns3), ddof=1))\n",
    "#print \"Portfolio volatility: \", vol_p_alt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ddof` parameter is a simple integer input that tells the function the number of degrees of freedom to take into account. This is a more statistical concept, but what this tells us that our matrix calculation is correct!\n",
    "\n",
    "A lot of this might not make sense at first glance. It helps to go back and forth between the theory and the code representations until you have a better grasp of the mathematics involved. It is definitely not necessary to be an expert on linear algebra and on matrix operations, but linear algebra can help to streamline the process of working with large amounts of data. For further reading on NumPy, check out the [documentation](https://docs.scipy.org/doc/numpy/user/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This presentation is for informational purposes only and does not constitute an offer to sell, a solicitation to buy, or a recommendation for any security; nor does it constitute an offer to provide investment advisory or other services by Quantopian, Inc. (\"Quantopian\"). Nothing contained herein constitutes investment advice or offers any opinion with respect to the suitability of any security, and any views expressed herein should not be taken as advice to buy, sell, or hold any security or as an endorsement of any security or company.  In preparing the information contained herein, Quantopian, Inc. has not taken into account the investment needs, objectives, and financial circumstances of any particular investor. Any views expressed and data illustrated herein were prepared based upon information, believed to be reliable, available to Quantopian, Inc. at the time of publication. Quantopian makes no guarantees as to their accuracy or completeness. All information is subject to change and may quickly become unreliable for various reasons, including changes in market conditions or economic circumstances.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
